{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced dynamic seq2seq with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we elected to manually feed `decoder_inputs` to better understand what is going on. Here we implement decoder with `tf.nn.raw_rnn` and will construct `decoder_inputs` step by step in the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections\n",
    "\n",
    "Here we manually setup input and output projections. It is necessary because we're implementing decoder with manual step transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projection(inputs, projection_size, scope):\n",
    "    input_size = inputs.get_shape()[-1].value \n",
    "    # inputs shape like [time, batch, input_size] or [batch, input_size]\n",
    "\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        W = tf.get_variable(name='W', shape=[input_size, projection_size],\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "        b = tf.get_variable(name='b', shape=[projection_size],\n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.constant_initializer(0, dtype=tf.float32))\n",
    "\n",
    "    input_shape = tf.unstack(tf.shape(inputs))\n",
    "\n",
    "    if len(input_shape) == 3:\n",
    "        time, batch, _ = input_shape  # dynamic parts of shape\n",
    "        inputs = tf.reshape(inputs, [-1, input_size])\n",
    "\n",
    "    elif len(input_shape) == 2:\n",
    "        batch, _depth = input_shape\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Wierd input shape: {}\".format(inputs))\n",
    "\n",
    "    linear = tf.add(tf.matmul(inputs, W), b)\n",
    "\n",
    "    if len(input_shape) == 3:\n",
    "        linear = tf.reshape(linear, [time, batch, projection_size])\n",
    "\n",
    "    return linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "We are replacing unidirectional `tf.nn.dynamic_rnn` with `tf.nn.bidirectional_dynamic_rnn` as the encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import (LSTMCell, LSTMStateTuple,\n",
    "                                    InputProjectionWrapper,\n",
    "                                    OutputProjectionWrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('EncoderInputProjection') as scope:\n",
    "    encoder_inputs_onehot = tf.one_hot(encoder_inputs, vocab_size)\n",
    "    encoder_inputs_projected = projection(encoder_inputs_onehot, input_embedding_size, scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'EncoderInputProjection/Reshape_1:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_projected,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to concatenate forward and backward outputs and state. In this case we will not discard outputs, they would be used for attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat_v2((encoder_fw_outputs, encoder_fw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat_v2(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat_v2(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## - encoder override with forward-only rnn\n",
    "# with tf.variable_scope('encoder_override'):\n",
    "#     encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "#         cell=encoder_cell,\n",
    "#         inputs=encoder_inputs_projected,\n",
    "#         dtype=tf.float32, time_major=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time and batch dimensions are dynamic, i.e. they can change in runtime, from batch to batch\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "\n",
    "# how far to run the decoder is our decision\n",
    "decoder_lengths = encoder_inputs_length + 3\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder without projection.\n",
    "Internal transition step uses beam search\n",
    "```\n",
    "output(t) -> output projection(t) -> prediction(t) (argmax) -> input projection(t+1) -> next input(t+1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder via `tf.nn.raw_rnn`\n",
    "\n",
    "`tf.nn.dynamic_rnn` allows for easy RNN construction, but is limited. For example, a nice way to increase robustness of the model is to feed as decoder inputs tokens that it previously generated, instead of shifted true sequence.\n",
    "\n",
    "![seq2seq-feed-previous](pictures/2-seq2seq-feed-previous.png)\n",
    "*Image borrowed from http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert EOS == 1\n",
    "assert PAD == 0\n",
    "\n",
    "eos_time_slice = tf.one_hot(\n",
    "    tf.ones([batch_size], \n",
    "            dtype=tf.int32, name='EOS'), \n",
    "    vocab_size, name='EOS_OneHot')\n",
    "\n",
    "pad_time_slice = tf.one_hot(\n",
    "    tf.zeros([batch_size], \n",
    "             dtype=tf.int32, name='PAD'),\n",
    "    vocab_size, name='PAD_OneHot')\n",
    "\n",
    "def loop_fn_initial(time, cell_output, cell_state, loop_state):\n",
    "    assert cell_output is None and loop_state is None and cell_state is None\n",
    "\n",
    "    elements_finished = (time >= decoder_lengths)  # all True at the 1st step\n",
    "    with tf.variable_scope('DecoderInputProjection') as scope:\n",
    "        initial_input = projection(eos_time_slice, input_embedding_size, scope)\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_loop_state = None # we don't need to pass any additional information\n",
    "    \n",
    "    return (elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            None, # cell output is dummy here\n",
    "            initial_loop_state)\n",
    "\n",
    "def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "    \"\"\" loop_fn determines transitions between RNN unroll steps\n",
    "    \"\"\"\n",
    "\n",
    "    if cell_state is None:    # time == 0\n",
    "        return loop_fn_initial(time, cell_output, cell_state, loop_state)\n",
    "    \n",
    "    emit_output = cell_output  # == None for time == 0\n",
    "\n",
    "    next_cell_state = cell_state\n",
    "\n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "\n",
    "    def pad_step():\n",
    "        with tf.variable_scope('DecoderInputProjection', reuse=True) as scope:\n",
    "            return projection(pad_time_slice, input_embedding_size, scope)\n",
    "        \n",
    "    def beam_step():\n",
    "        \"\"\" output->input transition:\n",
    "\n",
    "            output[t] -> output projection[t] -> prediction[t] ->\n",
    "            -> input[t+1] -> input projection[t+1]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('DecoderOutputProjection') as scope:\n",
    "            output = projection(cell_output, vocab_size, scope)\n",
    "        prediction = tf.argmax(output, axis=1)\n",
    "        prediction_onehot = tf.one_hot(prediction, vocab_size)\n",
    "        with tf.variable_scope('DecoderInputProjection', reuse=True) as scope:\n",
    "            projection_ = projection(prediction_onehot, input_embedding_size, scope)\n",
    "        return projection_\n",
    "    \n",
    "    next_input = tf.cond(finished, pad_step, beam_step)\n",
    "\n",
    "    next_loop_state = None\n",
    "\n",
    "    result = (elements_finished, \n",
    "            next_input, \n",
    "            next_cell_state,\n",
    "            emit_output,\n",
    "            next_loop_state)\n",
    "    \n",
    "    return result\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()\n",
    "\n",
    "with tf.variable_scope('DecoderOutputProjection') as scope:\n",
    "    decoder_logits = projection(decoder_outputs, vocab_size, scope)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN outputs tensor of shape `[max_time, batch_size, hidden_units]` which projection layer maps onto `[max_time, batch_size, vocab_size]`. `vocab_size` part of the shape is static, while `max_time` and `batch_size` is dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the toy task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the copy task â€” given a random sequence of integers from a `vocabulary`, learn to memorize and reproduce input sequence. Because sequences are random, they do not contain any structure, unlike natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[4, 4, 7, 3]\n",
      "[2, 8, 6, 9, 3, 9, 2]\n",
      "[8, 8, 6, 3, 7, 5]\n",
      "[6, 8, 4]\n",
      "[9, 3, 7, 3]\n",
      "[3, 9, 5, 8, 2]\n",
      "[5, 8, 3, 2, 7, 2, 4]\n",
      "[9, 4, 5, 4, 5, 3]\n",
      "[9, 5, 2, 4, 7, 2, 6, 6]\n",
      "[2, 9, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.296210765838623\n",
      "  sample 1:\n",
      "    input     > [2 4 6 0 0 0 0 0]\n",
      "    predicted > [9 4 0 4 4 4 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 3 2 6 3 9 0 0]\n",
      "    predicted > [1 1 1 4 4 4 4 4 4 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 2 5 5 6 0 0 0]\n",
      "    predicted > [9 1 1 0 0 4 4 4 0 0 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 1.0088521242141724\n",
      "  sample 1:\n",
      "    input     > [7 4 8 5 0 0 0 0]\n",
      "    predicted > [4 4 4 5 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 5 2 0 0 0 0 0]\n",
      "    predicted > [4 4 5 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 4 6 6 0 0 0 0]\n",
      "    predicted > [5 6 6 6 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.6323063969612122\n",
      "  sample 1:\n",
      "    input     > [9 6 7 6 0 0 0 0]\n",
      "    predicted > [9 6 6 6 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 8 4 4 3 3 7 5]\n",
      "    predicted > [8 8 4 3 3 3 5 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 6 7 0 0 0 0]\n",
      "    predicted > [2 9 9 7 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.41100767254829407\n",
      "  sample 1:\n",
      "    input     > [4 3 2 3 2 5 0 0]\n",
      "    predicted > [4 3 3 2 2 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 7 7 7 7 9 6 8]\n",
      "    predicted > [6 7 7 7 7 8 8 8 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 7 2 2 6 6 5 0]\n",
      "    predicted > [6 7 2 2 6 6 5 1 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.27289697527885437\n",
      "  sample 1:\n",
      "    input     > [9 5 5 5 5 7 6 2]\n",
      "    predicted > [9 5 5 5 5 2 2 1 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 9 6 4 0 0 0 0]\n",
      "    predicted > [9 9 6 4 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 4 7 3 7 9 0 0]\n",
      "    predicted > [2 4 7 7 7 9 1 0 0 0 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 0.16560326516628265\n",
      "  sample 1:\n",
      "    input     > [2 5 3 9 4 7 9 3]\n",
      "    predicted > [2 5 2 9 4 7 9 3 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 2 7 5 5 2 0 0]\n",
      "    predicted > [8 2 7 5 5 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 4 7 7 2 5 0 0]\n",
      "    predicted > [8 4 7 7 2 5 1 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.14504018425941467\n",
      "  sample 1:\n",
      "    input     > [8 2 7 9 0 0 0 0]\n",
      "    predicted > [8 2 7 9 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 8 7 7 9 9 2 0]\n",
      "    predicted > [3 8 7 7 9 9 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 5 2 4 8 6 0 0]\n",
      "    predicted > [7 5 2 4 8 6 1 0 0 0 0]\n",
      "\n",
      "batch 3500\n",
      "  minibatch loss: 0.09004990011453629\n",
      "  sample 1:\n",
      "    input     > [8 8 9 5 6 8 5 0]\n",
      "    predicted > [8 8 9 5 8 8 5 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 7 9 2 4 6 9 0]\n",
      "    predicted > [5 7 9 2 4 6 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 2 7 5 0 0 0 0]\n",
      "    predicted > [7 2 7 5 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss: 0.07691812515258789\n",
      "  sample 1:\n",
      "    input     > [3 7 8 6 2 2 0 0]\n",
      "    predicted > [3 7 8 6 2 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 3 7 7 0 0 0 0]\n",
      "    predicted > [6 3 7 7 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 8 4 0 0 0 0 0]\n",
      "    predicted > [4 8 4 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 4500\n",
      "  minibatch loss: 0.06792093068361282\n",
      "  sample 1:\n",
      "    input     > [3 5 7 0 0 0 0 0]\n",
      "    predicted > [3 5 7 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 5 2 4 9 3 5 0]\n",
      "    predicted > [8 5 2 4 9 3 5 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 5 3 0 0 0 0 0]\n",
      "    predicted > [5 5 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss: 0.048893190920352936\n",
      "  sample 1:\n",
      "    input     > [4 8 7 0 0 0 0 0]\n",
      "    predicted > [4 8 7 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 9 8 0 0 0 0 0]\n",
      "    predicted > [8 9 8 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 7 2 5 0 0 0]\n",
      "    predicted > [2 9 7 2 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 5500\n",
      "  minibatch loss: 0.055275142192840576\n",
      "  sample 1:\n",
      "    input     > [8 2 8 2 8 9 0 0]\n",
      "    predicted > [8 2 8 2 8 9 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 8 5 3 3 7 2 0]\n",
      "    predicted > [9 8 5 3 3 7 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 7 5 7 7 7 6 4]\n",
      "    predicted > [3 7 9 7 7 7 6 4 1 0 0]\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss: 0.0429999977350235\n",
      "  sample 1:\n",
      "    input     > [8 4 3 7 9 6 6 0]\n",
      "    predicted > [8 4 3 7 9 6 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 9 2 9 3 0 0 0]\n",
      "    predicted > [6 9 2 9 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 7 6 4 5 4 4 0]\n",
      "    predicted > [2 7 6 4 5 4 4 1 0 0 0]\n",
      "\n",
      "batch 6500\n",
      "  minibatch loss: 0.02837148681282997\n",
      "  sample 1:\n",
      "    input     > [6 5 8 3 0 0 0 0]\n",
      "    predicted > [6 5 8 3 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 7 3 0 0 0 0 0]\n",
      "    predicted > [4 7 3 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 7 2 2 6 6 6]\n",
      "    predicted > [9 6 7 2 2 6 6 6 1 0 0]\n",
      "\n",
      "batch 7000\n",
      "  minibatch loss: 0.025990689173340797\n",
      "  sample 1:\n",
      "    input     > [5 6 5 7 0 0 0 0]\n",
      "    predicted > [5 6 5 7 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 5 3 2 3 9 4 5]\n",
      "    predicted > [9 5 3 2 3 9 4 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 3 7 8 8 8 3 0]\n",
      "    predicted > [7 3 7 8 8 8 3 1 0 0 0]\n",
      "\n",
      "batch 7500\n",
      "  minibatch loss: 0.027143817394971848\n",
      "  sample 1:\n",
      "    input     > [2 7 7 5 7 0 0 0]\n",
      "    predicted > [2 7 7 5 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 2 7 5 5 0 0 0]\n",
      "    predicted > [5 2 7 5 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 3 0 0 0 0 0]\n",
      "    predicted > [8 5 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 8000\n",
      "  minibatch loss: 0.03677946701645851\n",
      "  sample 1:\n",
      "    input     > [8 9 2 8 2 4 0 0]\n",
      "    predicted > [8 9 2 8 2 4 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 5 3 3 8 7 0 0]\n",
      "    predicted > [4 5 3 3 8 7 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 6 5 6 5 7 8]\n",
      "    predicted > [9 6 6 5 6 5 7 8 1 0 0]\n",
      "\n",
      "batch 8500\n",
      "  minibatch loss: 0.0207744762301445\n",
      "  sample 1:\n",
      "    input     > [2 5 6 3 7 3 9 6]\n",
      "    predicted > [2 5 6 3 7 3 9 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 9 0 0 0 0 0]\n",
      "    predicted > [5 4 9 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 9 3 4 8 4 8 5]\n",
      "    predicted > [3 9 3 4 8 4 8 5 1 0 0]\n",
      "\n",
      "batch 9000\n",
      "  minibatch loss: 0.017769232392311096\n",
      "  sample 1:\n",
      "    input     > [9 2 7 2 8 6 7 5]\n",
      "    predicted > [9 2 7 2 8 6 7 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 6 7 4 0 0 0 0]\n",
      "    predicted > [7 6 7 4 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 7 7 2 6 4 5 6]\n",
      "    predicted > [9 7 7 2 6 4 5 6 1 0 0]\n",
      "\n",
      "batch 9500\n",
      "  minibatch loss: 0.015986036509275436\n",
      "  sample 1:\n",
      "    input     > [9 6 8 8 0 0 0 0]\n",
      "    predicted > [9 6 8 8 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 8 0 0 0 0 0]\n",
      "    predicted > [9 4 8 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 3 7 4 0 0 0 0]\n",
      "    predicted > [3 3 7 4 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 10000\n",
      "  minibatch loss: 0.01238623633980751\n",
      "  sample 1:\n",
      "    input     > [3 8 7 9 0 0 0 0]\n",
      "    predicted > [3 8 7 9 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 9 2 9 2 0 0 0]\n",
      "    predicted > [9 9 2 9 2 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 3 5 9 6 7 9 8]\n",
      "    predicted > [8 3 5 9 6 7 9 8 1 0 0]\n",
      "\n",
      "batch 10500\n",
      "  minibatch loss: 0.01224858034402132\n",
      "  sample 1:\n",
      "    input     > [8 5 6 3 6 3 0 0]\n",
      "    predicted > [8 5 6 3 6 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 2 8 2 3 0 0 0]\n",
      "    predicted > [5 2 8 2 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 5 3 4 9 7 9]\n",
      "    predicted > [4 4 4 3 4 9 7 9 1 0 0]\n",
      "\n",
      "batch 11000\n",
      "  minibatch loss: 0.01527827512472868\n",
      "  sample 1:\n",
      "    input     > [3 5 8 4 0 0 0 0]\n",
      "    predicted > [3 5 8 4 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 9 5 3 6 3 8 5]\n",
      "    predicted > [5 9 5 3 6 3 8 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 6 2 3 7 6 0 0]\n",
      "    predicted > [5 6 2 3 7 6 1 0 0 0 0]\n",
      "\n",
      "batch 11500\n",
      "  minibatch loss: 0.007602800149470568\n",
      "  sample 1:\n",
      "    input     > [5 6 5 8 8 8 9 0]\n",
      "    predicted > [5 6 5 8 8 8 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 6 3 5 5 6 8 0]\n",
      "    predicted > [5 6 3 5 5 6 8 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 3 3 7 0 0 0]\n",
      "    predicted > [8 5 3 3 7 1 0 0 0 0 0]\n",
      "\n",
      "batch 12000\n",
      "  minibatch loss: 0.009876254014670849\n",
      "  sample 1:\n",
      "    input     > [5 5 7 3 3 7 4 8]\n",
      "    predicted > [5 5 7 3 3 7 4 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 4 7 7 6 0 0 0]\n",
      "    predicted > [4 4 7 7 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 5 0 0 0 0 0]\n",
      "    predicted > [2 9 5 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 12500\n",
      "  minibatch loss: 0.009893779642879963\n",
      "  sample 1:\n",
      "    input     > [5 8 4 5 9 2 6 0]\n",
      "    predicted > [5 8 4 5 9 2 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 4 5 5 3 8 4 4]\n",
      "    predicted > [6 4 5 5 3 8 4 4 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 2 0 0 0 0 0]\n",
      "    predicted > [4 2 2 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 13000\n",
      "  minibatch loss: 0.010787930339574814\n",
      "  sample 1:\n",
      "    input     > [9 8 9 8 8 0 0 0]\n",
      "    predicted > [9 8 9 8 8 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 8 7 6 7 4 7 0]\n",
      "    predicted > [7 8 7 6 7 4 7 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 9 9 4 8 9 5 0]\n",
      "    predicted > [3 9 9 4 8 9 5 1 0 0 0]\n",
      "\n",
      "batch 13500\n",
      "  minibatch loss: 0.006298038177192211\n",
      "  sample 1:\n",
      "    input     > [6 5 6 9 8 2 4 4]\n",
      "    predicted > [6 5 6 9 8 2 4 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 4 5 5 5 8 6 0]\n",
      "    predicted > [4 4 5 5 5 8 6 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 4 7 3 7 4 0 0]\n",
      "    predicted > [2 4 7 3 7 4 1 0 0 0 0]\n",
      "\n",
      "batch 14000\n",
      "  minibatch loss: 0.004350936971604824\n",
      "  sample 1:\n",
      "    input     > [5 9 8 9 2 9 0 0]\n",
      "    predicted > [5 9 8 9 2 9 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 2 4 9 6 2 4 0]\n",
      "    predicted > [4 2 4 9 6 2 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 2 3 3 2 6 0 0]\n",
      "    predicted > [8 2 3 3 2 6 1 0 0 0 0]\n",
      "\n",
      "batch 14500\n",
      "  minibatch loss: 0.00667122146114707\n",
      "  sample 1:\n",
      "    input     > [4 5 5 0 0 0 0 0]\n",
      "    predicted > [4 5 5 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 7 9 3 0 0 0 0]\n",
      "    predicted > [9 7 9 3 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 5 3 9 0 0 0 0]\n",
      "    predicted > [6 5 3 9 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 15000\n",
      "  minibatch loss: 0.010186548344790936\n",
      "  sample 1:\n",
      "    input     > [6 8 4 0 0 0 0 0]\n",
      "    predicted > [6 8 4 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 6 3 6 5 2 0 0]\n",
      "    predicted > [7 6 3 6 5 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 9 5 4 2 9 9]\n",
      "    predicted > [4 2 9 5 4 2 9 9 1 0 0]\n",
      "\n",
      "batch 15500\n",
      "  minibatch loss: 0.007274122443050146\n",
      "  sample 1:\n",
      "    input     > [9 3 5 6 3 8 9 0]\n",
      "    predicted > [9 3 5 6 3 8 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 4 8 4 2 0 0]\n",
      "    predicted > [2 3 4 8 4 2 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 4 2 8 0 0 0 0]\n",
      "    predicted > [8 4 2 8 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 16000\n",
      "  minibatch loss: 0.009255490265786648\n",
      "  sample 1:\n",
      "    input     > [9 7 8 6 8 8 4 2]\n",
      "    predicted > [9 7 8 6 8 8 4 2 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 5 5 0 0 0 0 0]\n",
      "    predicted > [2 5 5 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 6 3 9 7 0 0 0]\n",
      "    predicted > [2 6 3 9 7 1 0 0 0 0 0]\n",
      "\n",
      "batch 16500\n",
      "  minibatch loss: 0.008886381052434444\n",
      "  sample 1:\n",
      "    input     > [8 4 4 2 6 4 7 4]\n",
      "    predicted > [8 4 2 2 6 4 7 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 2 8 4 0 0 0 0]\n",
      "    predicted > [6 2 8 4 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 3 9 4 4 3 4]\n",
      "    predicted > [2 9 3 9 4 4 3 4 1 0 0]\n",
      "\n",
      "batch 17000\n",
      "  minibatch loss: 0.0045090774074196815\n",
      "  sample 1:\n",
      "    input     > [5 4 3 6 3 2 3 6]\n",
      "    predicted > [5 4 3 6 3 2 3 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 3 3 8 5 6 3 0]\n",
      "    predicted > [4 3 3 8 5 6 3 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 3 0 0 0 0 0]\n",
      "    predicted > [2 8 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 17500\n",
      "  minibatch loss: 0.0033323345705866814\n",
      "  sample 1:\n",
      "    input     > [4 9 8 8 3 3 7 4]\n",
      "    predicted > [4 9 8 8 3 3 7 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 2 6 9 4 9 0]\n",
      "    predicted > [5 4 2 6 9 4 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 6 6 2 7 2 6 9]\n",
      "    predicted > [4 6 6 2 7 2 6 9 1 0 0]\n",
      "\n",
      "batch 18000\n",
      "  minibatch loss: 0.002411414170637727\n",
      "  sample 1:\n",
      "    input     > [6 4 6 2 7 0 0 0]\n",
      "    predicted > [6 4 6 2 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 3 4 2 4 9 0]\n",
      "    predicted > [5 5 3 4 2 4 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 4 8 4 6 0 0 0]\n",
      "    predicted > [3 4 8 4 6 1 0 0 0 0 0]\n",
      "\n",
      "batch 18500\n",
      "  minibatch loss: 0.0037261091638356447\n",
      "  sample 1:\n",
      "    input     > [6 8 4 7 0 0 0 0]\n",
      "    predicted > [6 8 4 7 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 7 6 0 0 0 0 0]\n",
      "    predicted > [4 7 6 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 2 2 4 5 2 4 7]\n",
      "    predicted > [9 2 2 4 5 2 4 7 1 0 0]\n",
      "\n",
      "batch 19000\n",
      "  minibatch loss: 0.0027516784612089396\n",
      "  sample 1:\n",
      "    input     > [4 3 2 9 7 9 7 9]\n",
      "    predicted > [4 3 2 9 7 9 7 9 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 4 4 6 7 5 9 0]\n",
      "    predicted > [4 4 4 6 7 5 9 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 7 3 0 0 0 0 0]\n",
      "    predicted > [9 7 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 19500\n",
      "  minibatch loss: 0.005561848636716604\n",
      "  sample 1:\n",
      "    input     > [9 9 7 3 2 7 7 0]\n",
      "    predicted > [9 9 7 3 2 7 7 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 6 9 7 6 0 0 0]\n",
      "    predicted > [5 6 9 7 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 9 5 6 3 0 0]\n",
      "    predicted > [7 8 9 5 6 3 1 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 10000\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0041 after 2000000 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11053e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is definitely getting learned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
