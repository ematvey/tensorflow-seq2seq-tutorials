{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced dynamic seq2seq with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UPDATE (16.02.2017)**: I learned some things after I writing this tutorial. In particular:\n",
    " - Replacing projection (one-hot encoding followed by linear layer) with embedding (indexing weights of linear layer directly) is more efficient.\n",
    " - When decoding, feeding previously generated tokens as inputs adds robustness to model's errors. However feeding ground truth speeds up training. Apperantly best practice is to mix both randomly when training.\n",
    "I will update tutorial to reflect this at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we elected to manually feed `decoder_inputs` to better understand what is going on. Here we implement decoder with `tf.nn.raw_rnn` and will construct `decoder_inputs` step by step in the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections\n",
    "\n",
    "Here we manually setup input and output projections. It is necessary because we're implementing decoder with manual step transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projection(inputs, projection_size, scope):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: shape like [time, batch, input_size] or [batch, input_size]\n",
    "        projection_size: int32\n",
    "        scope: outer variable scope\n",
    "    \"\"\"\n",
    "    input_size = inputs.get_shape()[-1].value \n",
    "\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        W = tf.get_variable(name='W', shape=[input_size, projection_size],\n",
    "                            dtype=tf.float32)\n",
    "\n",
    "        b = tf.get_variable(name='b', shape=[projection_size],\n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.constant_initializer(0, dtype=tf.float32))\n",
    "\n",
    "    input_shape = tf.unstack(tf.shape(inputs))\n",
    "\n",
    "    if len(input_shape) == 3:\n",
    "        time, batch, _ = input_shape  # dynamic parts of shape\n",
    "        inputs = tf.reshape(inputs, [-1, input_size])\n",
    "\n",
    "    elif len(input_shape) == 2:\n",
    "        batch, _depth = input_shape\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Wierd input shape: {}\".format(inputs))\n",
    "\n",
    "    linear = tf.add(tf.matmul(inputs, W), b)\n",
    "\n",
    "    if len(input_shape) == 3:\n",
    "        linear = tf.reshape(linear, [time, batch, projection_size])\n",
    "\n",
    "    return linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "We are replacing unidirectional `tf.nn.dynamic_rnn` with `tf.nn.bidirectional_dynamic_rnn` as the encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import (LSTMCell, LSTMStateTuple,\n",
    "                                    InputProjectionWrapper,\n",
    "                                    OutputProjectionWrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('EncoderInputProjection') as scope:\n",
    "    encoder_inputs_onehot = tf.one_hot(encoder_inputs, vocab_size)\n",
    "    encoder_inputs_projected = projection(encoder_inputs_onehot, input_embedding_size, scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'EncoderInputProjection/Reshape_1:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_projected,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ReverseSequence:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to concatenate forward and backward outputs and state. In this case we will not discard outputs, they would be used for attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_fw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## - encoder override with forward-only rnn\n",
    "# with tf.variable_scope('encoder_override'):\n",
    "#     encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "#         cell=encoder_cell,\n",
    "#         inputs=encoder_inputs_projected,\n",
    "#         dtype=tf.float32, time_major=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time and batch dimensions are dynamic, i.e. they can change in runtime, from batch to batch\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "\n",
    "# how far to run the decoder is our decision\n",
    "decoder_lengths = encoder_inputs_length + 3\n",
    "# +2 additional steps, +1 leading <EOS> token for decoder inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder without projection.\n",
    "Internal transition step uses greedy search:\n",
    "```\n",
    "output(t) -> output projection(t) -> prediction(t) (argmax) -> input projection(t+1) -> next input(t+1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder via `tf.nn.raw_rnn`\n",
    "\n",
    "`tf.nn.dynamic_rnn` allows for easy RNN construction, but is limited. For example, a nice way to increase robustness of the model is to feed as decoder inputs tokens that it previously generated, instead of shifted true sequence.\n",
    "\n",
    "![seq2seq-feed-previous](pictures/2-seq2seq-feed-previous.png)\n",
    "*Image borrowed from http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert EOS == 1\n",
    "assert PAD == 0\n",
    "\n",
    "eos_time_slice = tf.one_hot(\n",
    "    tf.ones([batch_size], \n",
    "            dtype=tf.int32, name='EOS'), \n",
    "    vocab_size, name='EOS_OneHot')\n",
    "\n",
    "pad_time_slice = tf.one_hot(\n",
    "    tf.zeros([batch_size], \n",
    "             dtype=tf.int32, name='PAD'),\n",
    "    vocab_size, name='PAD_OneHot')\n",
    "\n",
    "def loop_fn_initial(time, cell_output, cell_state, loop_state):\n",
    "    assert cell_output is None and loop_state is None and cell_state is None\n",
    "\n",
    "    elements_finished = (time >= decoder_lengths)  # all True at the 1st step\n",
    "    with tf.variable_scope('DecoderInputProjection') as scope:\n",
    "        initial_input = projection(eos_time_slice, input_embedding_size, scope)\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    \n",
    "    return (elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            None,  # cell output is dummy here\n",
    "            initial_loop_state)\n",
    "\n",
    "def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "    \"\"\" loop_fn determines transitions between RNN unroll steps\n",
    "    \"\"\"\n",
    "\n",
    "    if cell_state is None:    # time == 0\n",
    "        return loop_fn_initial(time, cell_output, cell_state, loop_state)\n",
    "    \n",
    "    emit_output = cell_output  # == None for time == 0\n",
    "\n",
    "    next_cell_state = cell_state\n",
    "\n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "\n",
    "    def padded_next_input():\n",
    "        with tf.variable_scope('DecoderInputProjection', reuse=True) as scope:\n",
    "            return projection(pad_time_slice, input_embedding_size, scope)\n",
    "        \n",
    "    def search_for_next_input():\n",
    "        \"\"\" output->input transition:\n",
    "\n",
    "            output[t] -> output projection[t] -> prediction[t] ->\n",
    "            -> input[t+1] -> input projection[t+1]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope('DecoderOutputProjection') as scope:\n",
    "            output = projection(cell_output, vocab_size, scope)\n",
    "        prediction = tf.argmax(output, axis=1)\n",
    "        prediction_onehot = tf.one_hot(prediction, vocab_size)\n",
    "        with tf.variable_scope('DecoderInputProjection', reuse=True) as scope:\n",
    "            projection_ = projection(prediction_onehot, input_embedding_size, scope)\n",
    "        return projection_\n",
    "    \n",
    "    next_input = tf.cond(finished, padded_next_input, search_for_next_input)\n",
    "\n",
    "    next_loop_state = None\n",
    "\n",
    "    result = (elements_finished, \n",
    "            next_input, \n",
    "            next_cell_state,\n",
    "            emit_output,\n",
    "            next_loop_state)\n",
    "    \n",
    "    return result\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()\n",
    "\n",
    "with tf.variable_scope('DecoderOutputProjection') as scope:\n",
    "    decoder_logits = projection(decoder_outputs, vocab_size, scope)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN outputs tensor of shape `[max_time, batch_size, hidden_units]` which projection layer maps onto `[max_time, batch_size, vocab_size]`. `vocab_size` part of the shape is static, while `max_time` and `batch_size` is dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the toy task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the copy task â€” given a random sequence of integers from a `vocabulary`, learn to memorize and reproduce input sequence. Because sequences are random, they do not contain any structure, unlike natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[8, 9, 6, 8, 2, 4, 2, 4]\n",
      "[7, 3, 3, 5, 8]\n",
      "[6, 3, 7, 5, 7, 9]\n",
      "[5, 7, 3, 9, 5, 9, 9, 4]\n",
      "[3, 7, 9, 9, 5, 8]\n",
      "[9, 4, 4]\n",
      "[7, 3, 2, 3]\n",
      "[2, 8, 3, 7, 2, 5]\n",
      "[6, 2, 7, 9, 8, 4, 4]\n",
      "[9, 3, 9, 9, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.2984840869903564\n",
      "  sample 1:\n",
      "    input     > [5 3 4 0 0 0 0 0]\n",
      "    predicted > [8 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 2 5 2 5 6 7 7]\n",
      "    predicted > [7 0 0 0 0 0 0 0 3 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 4 4 6 0 0 0 0]\n",
      "    predicted > [7 7 0 0 3 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.60413658618927\n",
      "  sample 1:\n",
      "    input     > [4 7 7 9 3 0 0 0]\n",
      "    predicted > [4 7 7 7 3 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 5 4 9 3 0 0 0]\n",
      "    predicted > [8 5 9 9 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 9 0 0 0 0 0]\n",
      "    predicted > [2 8 9 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.2828637659549713\n",
      "  sample 1:\n",
      "    input     > [8 2 4 0 0 0 0 0]\n",
      "    predicted > [8 2 4 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 2 3 0 0 0 0 0]\n",
      "    predicted > [9 2 3 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 5 4 4 8 2 8 9]\n",
      "    predicted > [3 5 4 4 4 8 8 9 1 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.1508026272058487\n",
      "  sample 1:\n",
      "    input     > [7 7 2 3 7 4 5 9]\n",
      "    predicted > [7 7 2 2 4 4 5 9 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 8 7 9 5 7 0 0]\n",
      "    predicted > [9 8 7 9 5 7 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 8 2 7 7 7 0 0]\n",
      "    predicted > [5 8 2 7 7 7 1 0 0 0 0]\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss: 0.08959022164344788\n",
      "  sample 1:\n",
      "    input     > [5 6 3 0 0 0 0 0]\n",
      "    predicted > [5 6 3 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 4 5 5 5 9 0 0]\n",
      "    predicted > [2 4 5 5 5 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 6 5 6 4 0 0 0]\n",
      "    predicted > [4 6 5 6 4 1 0 0 0 0 0]\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss: 0.07438583672046661\n",
      "  sample 1:\n",
      "    input     > [2 3 8 0 0 0 0 0]\n",
      "    predicted > [2 3 8 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 6 4 3 8 4 9]\n",
      "    predicted > [2 8 6 4 3 8 4 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 5 7 3 5 0 0 0]\n",
      "    predicted > [9 5 7 3 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss: 0.04925353452563286\n",
      "  sample 1:\n",
      "    input     > [4 2 4 3 2 9 0 0]\n",
      "    predicted > [4 2 4 3 2 9 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 2 0 0 0 0 0]\n",
      "    predicted > [2 8 2 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 7 5 0 0 0 0 0]\n",
      "    predicted > [9 7 5 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 7000\n",
      "  minibatch loss: 0.020021965727210045\n",
      "  sample 1:\n",
      "    input     > [8 2 8 7 9 0 0 0]\n",
      "    predicted > [8 2 8 7 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 6 7 4 0 0 0 0]\n",
      "    predicted > [2 6 7 4 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 3 3 5 4 6 0 0]\n",
      "    predicted > [9 3 3 5 4 6 1 0 0 0 0]\n",
      "\n",
      "batch 8000\n",
      "  minibatch loss: 0.021686488762497902\n",
      "  sample 1:\n",
      "    input     > [8 9 5 0 0 0 0 0]\n",
      "    predicted > [8 9 5 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 2 9 4 6 9 4 8]\n",
      "    predicted > [3 2 9 4 6 9 4 8 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 8 7 6 0 0 0 0]\n",
      "    predicted > [9 8 7 6 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 9000\n",
      "  minibatch loss: 0.010890339501202106\n",
      "  sample 1:\n",
      "    input     > [3 2 7 8 2 8 2 7]\n",
      "    predicted > [3 2 2 8 2 8 2 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 5 5 7 3 3 0 0]\n",
      "    predicted > [3 5 5 7 3 3 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 8 6 8 3 3 3 0]\n",
      "    predicted > [4 8 6 8 3 3 3 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 10000\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0120 after 1000000 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a8f54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
